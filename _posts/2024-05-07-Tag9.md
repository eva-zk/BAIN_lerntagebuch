---
title: "Einheit 7: Metadaten modellieren und Schnittstellen nutzen B"
date: 2024-05-07
---
Weitere Informationen erhältst Du über den Link: 
<a href="https://pad.gwdg.de/vv-Q4RDnQ22Gqc-EEgbewA#">BAIN HedgeDoc</a>

**Schnittstellen**

**1 Austauschprotokolle für Metadaten**

Beispiele (häufig verwendet):
- Z39.50: sehr alt, wird aber immer noch verwendet.
- SRU und OAI-PMH: gezielter Datenabruf, am besten für grössere Datenabrufe und regelmässige Aktualisierungen.

**2 OAI-PMH und VuFindHarvest**

OAI-PMH leicht erklärt: ein Protokoll, das auf Medata Harvesting basiert. Es gibt zwei Teilnehmer: Datenanbieter und Dienstanbieter. Harvesting bedeutet, dass man die in einem Repositorium verfügbaren Medadaten oder einen Teil davon anfordern, anfragen kann (<a href="https://www.openarchives.org/OAI/openarchivesprotocol.html">Quelle</a>). Das Produkt des Harvestings, sozusagen die Art des Inhalts, der für alle OAI-PMG-Anfragen zurückgegeben wird, wurde ebenfalls angeschaut.

Wir haben VuFindHarvest verwendet, um die Daten zu sammeln. VuFindHarvest ist ein Tool, das es ermöglicht, Metadaten aus einem oder mehreren Repositories in ein oder mehrere Directories zu ernten.

**3 Konvertierung: XSLT Crosswalk**

Daten, die wir in verschiedenen Formaten erhalten haben, können dann in MARC21-XML konvertiert werden. Crosswalk aus der Familie der Crosswalk Plugins übernimmt dann das Mapping (beinhaltet Regeln und ordnet die Elemente zu Werten).

**4 Konvertierung: MarcEdit**

Ein weiteres Tool, das verwendet werden kann, leider nicht Open Source, ist MarcEdit. Es hat eine einfach zu bedienende Oberfläche und kann sowohl einfache Such- und Ersetzungsaufgaben als auch extrem komplizierte Transformationen durchführen. Die Funktionalitäten des Tools werden noch erweitert und können dazu führen, dass es  noch weitere Arbeit und Verbindungen mit Linked Data, Bibliothekskataloge gibt (<a href="https://journal.code4lib.org/articles/16078?utm_source=rss&utm_medium=rss&utm_campaign=core-concepts-and-techniques-for-library-metadata-analysis" >Quelle</a>).

**(UN-)BEANTWORTETE FRAGEN:**

Wenn ich mir das Diagramm ansehe, das uns zur Verfügung gestellt wurde, kann ich die Schritte erkennen, die unternommen werden können:

<img src="/BAIN_lerntagebuch/docs/assets/images/12_Screenshot_2024_05_7.png" alt="Graph">

Wir können sehen, dass wir von Koha, ArchivesSpace und DSpace zu einem einheitlichen Datenformat gekommen sind. Da wir zuvor über verlorene Daten gesprochen haben, frage ich mich, wie viele Informationen auf diese Weise verloren gehen. Vor allem, wenn man dem Dublin Core folgt, der eine begrenzte Anzahl von 15 Elementen hat, kann ich mir vorstellen, dass eine Menge Metadaten verloren gehen könnten. Ich kann mir denken, dass zusätzlich zu den semantischen und kontextuellen Verlusten auch strukturelle Verluste auftreten, d. h. verlorene Beziehungen zwischen den Teilen der ursprünglichen Daten. Ich denke, ich kann keine allgemeine Frage wie diese stellen, dazu müsste ich mehr über die Daten wissen und wofür sie verwendet werden. Oder ist es eher eine Frage, ob es andere Optionen gibt, bei denen mehr Metadaten erhalten bleiben?
